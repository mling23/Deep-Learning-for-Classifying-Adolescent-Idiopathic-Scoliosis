#Import Libraries 
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms 
import math
from skimage import io
import os
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
from PIL import Image
import cv2
from google.colab.patches import cv2_imshow
import PIL
import torch.optim as optim

#hyper parameters
num_epochs = 4
batch_size = 4
num_classes = 7
in_channel = 1
learning_rate = .001
classes = ("0","1","2","3","4","5","6")
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class SpineImages(Dataset):
  def __init__(self, csv_file, root_dir, transform = None):
    self.annotations = pd.read_csv(csv_file)
    self.root_dir = root_dir
    self.transform = transform
  def __len__(self):
    return len(self.annotations)
  def __getitem__(self,index):
    img_path = os.path.join(self.root_dir,self.annotations.iloc[index,0])
    image = io.imread(img_path)
    y_label = torch.tensor(int(self.annotations.iloc[index,1]))

    if self.transform:
      image = self.transform(image)
    return(image,y_label)
    
    dataset = SpineImages(csv_file = "/content/drive/MyDrive/Colab Notebooks/Spine Labels - Sheet1.csv", root_dir ="/content/drive/MyDrive/Dataset", transform = transforms.ToTensor(),)
print(len(dataset))
train_set, test_set = torch.utils.data.random_split(dataset,[360,120])
train_loader = DataLoader(dataset = train_set, batch_size = batch_size, shuffle = True)
test_loader =  DataLoader(dataset = test_set, batch_size = batch_size, shuffle = True)

class CNN(nn.Module):
  def __init__(self, in_channels = 1, num_classes = 7):
    super(CNN, self).__init__()
    self.conv1 = nn.Conv2d(in_channels=1, out_channels= 8, kernel_size = (3,3), stride = (1,1), padding = (1,1))
    self.pool = nn.MaxPool2d(2,2)
    self.conv2 = nn.Conv2d(in_channels=8, out_channels= 16, kernel_size = (3,3), stride = (1,1), padding = (1,1))
    self.fc1 = nn.Linear(16*64*128,num_classes)
  def forward(self,x):
    x = F.relu(self.conv1(x))
    x = self.pool(x)
    x = F.relu(self.conv2(x))
    x = self.pool(x)
    x = x.reshape(x.shape[0],-1)
    x = self.fc1(x)
    return x 

model = CNN().to(device)


criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

n_total_steps = len(train_loader)
#Training 
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
       
        images = images.to(device)
        labels = labels.to(device)

        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)

        # Backward and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (i+1) % 5 == 0:
            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')

print('Finished Training')
PATH = './cnn.pth'
torch.save(model.state_dict(), PATH)
#Accuracy 
with torch.no_grad():
    n_correct = 0
    n_samples = 0
    n_class_correct = [0 for i in range(7)]
    n_class_samples = [0 for i in range(7)]
    for images, labels in test_loader:
        
        outputs = model(images)
        
        _, predicted = torch.max(outputs, 1)
        n_samples += labels.size(0)
        n_correct += (predicted == labels).sum().item()
        
        for i in range(4):
            label = labels[i]
            pred = predicted[i]
            if (label == pred):
                n_class_correct[label] += 1
            n_class_samples[label] += 1

    acc = 100.0 * n_correct / n_samples
    print(f'Accuracy of the network: {acc} %')
print(n_class_correct)
print(n_class_samples)

for i in range (7):
  if (n_class_samples[i] == 0):
    continue
  acc = 100.0 * n_class_correct[i] / n_class_samples[i]
  print(f'Accuracy of {classes[i]}: {acc} %')
